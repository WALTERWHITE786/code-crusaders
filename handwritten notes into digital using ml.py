# -*- coding: utf-8 -*-
"""HTR WITH OCR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VgJnLuUSJR59DV92LQ6fWDOHl8oDrgr-

#HTR USING TENSORFLOW

#libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""#read dataset"""

data = pd.read_csv('A_Z Handwritten Data.csv').astype('float32')
data.head(10)

"""#splitting of data"""

X = data.drop('0',axis = 1)
y = data['0']

"""#Performing Split Using Sklearn:"""

from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)

shuffle_data = shuffle(x_train)

import cv2
import numpy as np
import matplotlib.pyplot as plt


fig, axes = plt.subplots(3, 3, figsize=(10, 10))
axes = axes.flatten()

for i in range(9):
    image = np.reshape(shuffle_data[i], (28, 28))
    _, shu = cv2.threshold(image, 30, 200, cv2.THRESH_BINARY)
    axes[i].imshow(shu, cmap="Greys")
    axes[i].axis("off")

plt.show()

"""#training of our model"""

x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)
x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2],1)
print("New shape of training data: ", x_train.shape)
print("New shape of testing data: ", x_test.shape)

import tensorflow as tf
from tensorflow.keras.utils import to_categorical

# Ensure y_train and y_test contain labels in range [0, 25]
y_training = to_categorical(y_train, num_classes=26)  # Default dtype is float32
y_testing = to_categorical(y_test, num_classes=26)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout
from tensorflow.keras.optimizers import SGD, Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping

model = Sequential()

model.add(Conv2D(64 , (3, 3), activation='relu', input_shape=(28,28,1)))
model.add(MaxPool2D(2, 2))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPool2D(2, 2))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPool2D(2,2))

model.add(Flatten())

model.add(Dense(128,activation ="relu"))
model.add(Dense(256,activation ="relu"))
model.add(Dense(26,activation ="softmax"))

model.summary()

model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_training, epochs=2,  validation_data = (x_test,y_testing))

model.save(r'handwritten_character_recog_model.h5')

words = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}

fig, axes = plt.subplots(3,3, figsize=(8,9))
axes = axes.flatten()
for i,ax in enumerate(axes):
    image = np.reshape(x_test[i], (28,28))
    ax.imshow(image, cmap="Greys")
    pred = words[np.argmax(y_testing[i])]
    ax.set_title("Prediction: "+pred)
    ax.grid()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load Image
image = cv2.imread('line.png')

# Check if image exists
if image is None:
    print("Error: Image file 'line.png' not found.")
    exit()

# Convert to Grayscale
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Apply Binary Thresholding (Converts to Black & White)
_, binary_image = cv2.threshold(gray_image, 100, 255, cv2.THRESH_BINARY_INV)

# Resize to 28x28 for ML Models (if needed)
resized_image = cv2.resize(binary_image, (28, 28))

# Normalize Pixel Values (Scale from 0-255 to 0-1)
normalized_image = resized_image.astype('float32') / 255.0

# Display Images
plt.figure(figsize=(10, 4))

plt.subplot(1, 3, 1)
plt.imshow(gray_image, cmap='gray')
plt.title('Grayscale')

plt.subplot(1, 3, 2)
plt.imshow(binary_image, cmap='gray')
plt.title('Binary (Thresholded)')

plt.subplot(1, 3, 3)
plt.imshow(resized_image, cmap='gray')
plt.title('Resized for ML')

plt.show()

# Reshape for TensorFlow Model (if needed)
final_image = np.reshape(normalized_image, (1, 28, 28, 1))

pip install easyocr opencv-python matplotlib

import cv2
import easyocr
import matplotlib.pyplot as plt

# Load Image
image = cv2.imread('line.png')

# Convert to Grayscale
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Display Image
plt.imshow(gray_image, cmap='gray')
plt.title("Processed Image for OCR")
plt.axis("off")
plt.show()

# Initialize EasyOCR Reader
reader = easyocr.Reader(['en'])  # English Language

# Extract Text
extracted_text = reader.readtext(gray_image, detail=0)

# Print Extracted Text
print("\nüìù Extracted Digital Text:\n")
print(" ".join(extracted_text))

import cv2
import easyocr
import matplotlib.pyplot as plt

# Load Image
image = cv2.imread('word.png')

# Convert to Grayscale
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Display Image
plt.imshow(gray_image, cmap='gray')
plt.title("Processed Image for OCR")
plt.axis("off")
plt.show()

# Initialize EasyOCR Reader
reader = easyocr.Reader(['en'])  # English Language

# Extract Text
extracted_text = reader.readtext(gray_image, detail=0)

# Print Extracted Text
print("\nüìù Extracted Digital Text:\n")
print(" ".join(extracted_text))

import cv2
import easyocr
import matplotlib.pyplot as plt

# Load Image
image = cv2.imread('word.png')

# Convert to Grayscale
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Display Image
plt.imshow(gray_image, cmap='gray')
plt.title("Processed Image for OCR")
plt.axis("off")
plt.show()

# Initialize EasyOCR Reader
reader = easyocr.Reader(['en'])  # English Language

# Extract Text
extracted_text = reader.readtext(gray_image, detail=0)

# Print Extracted Text
print("\nüìù Extracted Digital Text:\n")
print(" ".join(extracted_text))

import cv2
import easyocr
import matplotlib.pyplot as plt

# Load Image
image = cv2.imread('a01-132.png')

# Convert to Grayscale
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Display Image
plt.imshow(gray_image, cmap='gray')
plt.title("Processed Image for OCR")
plt.axis("off")
plt.show()

# Initialize EasyOCR Reader
reader = easyocr.Reader(['en'])  # English Language

# Extract Text
extracted_text = reader.readtext(gray_image, detail=0)

# Print Extracted Text
print("\nüìù Extracted Digital Text:\n")
print(" ".join(extracted_text))

import cv2
import easyocr
import matplotlib.pyplot as plt

# Load Image
image = cv2.imread('a01-132.png')

# Convert to Grayscale
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Display Image
plt.imshow(gray_image, cmap='gray')
plt.title("Processed Image for OCR")
plt.axis("off")
plt.show()

# Initialize EasyOCR Reader
reader = easyocr.Reader(['en'])  # English Language

# Extract Text
extracted_text = reader.readtext(gray_image, detail=0)

# Print Extracted Text
print("\nüìù Extracted Digital Text:\n")
print(" ".join(extracted_text))